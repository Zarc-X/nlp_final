# 基于本地大模型的代码生成与自我演化系统

## 项目简介

本项目是一个代码生成推理系统研究项目，聚焦于探索在代码生成领域实现高效推理和持续自我演进的方法论。项目基于AGI（通用人工智能）发展路径中OpenAI提出的“推理者”阶段，旨在构建一个具备自我演进能力的代码生成系统原型。

## 目录结构

      qwen-coder-evolution/
      │
      ├── main.py                    # 主程序入口
      ├── config.py                  # 配置管理
      │
      ├── core/                      # 核心功能模块
      │   ├── __init__.py
      │   ├── model_manager.py       # 模型管理
      │   ├── api_client.py          # API调用
      │   ├── code_processor.py      # 代码处理与验证
      │   ├── model_evaluation.py    # 模型评估模块
      │   ├── fine_tune_manager.py   # 微调管理模块
      │   └── evolution_core.py      # 自我演化核心逻辑
      │
      ├── data/                      # 数据管理模块
      │   ├── __init__.py
      │   ├── training_data.py       # 训练数据处理
      │   └── file_manager.py        # 文件管理
      │
      ├── utils/                     # 工具函数
      │   ├── __init__.py
      │   ├── text_utils.py          # 文本处理
      │   ├── progress_tracker.py    # 进度跟踪
      │   └── validation_utils.py    # 验证工具
      │
      ├── ui/                        # 界面相关
      │   ├── __init__.py
      │   ├── gradio_interface.py    # Gradio界面
      │   └── event_handlers.py      # 事件处理
      │
      ├── models/                    # 模型目录（保持不变）
      ├── evolution_training_data/   # 训练数据目录（保持不变）
      └── model_checkpoints/         # 模型检查点目录（保持不变）


## 研究背景与目标

- **研究背景**：当前大模型在复杂推理上仍存在局限，推理成本高，且缺乏自我演进能力。代码生成作为复杂推理的典型场景，被视为验证AGI核心算法的理想试验场。
- **核心目标**：构建一个具备自我演进能力的代码生成推理系统，实现持续自我改进。
- **预期成果**：一个可演示的自我改进代码生成系统原型。

## 核心功能

### 1. 本地代码生成
- 支持 Qwen2.5-Coder-0.5B/1.5B 本地模型部署
- 提供交互式代码生成界面
- 支持自定义系统提示词、温度、top-p 等生成参数
- 自动适配 GPU/CPU 运行环境

### 2. 模型评估系统
- 集成 HumanEval 数据集（164个编程任务）
- 自动执行代码并验证正确性
- 实时显示评估进度和通过率
- 详细的错误分类（语法错误、逻辑错误、测试失败等）

### 3. **复杂推理能力**
- 支持多轮对话和上下文理解
- 能够处理复杂的编程任务和需求分析
- 通过系统提示词引导模型进行深度思考
- 支持长文本代码生成（最大2048 tokens）

### 4. **自我演化机制** 
自我演化是本项目的核心创新功能，实现了模型的自动优化和持续学习：

#### 工作流程
1. **高质量代码生成**：使用 qwen2.5-coder-32b-instruct API 生成高质量代码
2. **语法验证**：自动检查生成代码的语法正确性
3. **逻辑验证**：使用 qwen2.5-coder-14b-instruct API 判断代码是否符合用户需求
4. **数据收集**：通过验证的 (instruct, code) 二元组自动收集为训练数据
5. **模型微调**：使用收集的高质量数据微调本地 1.5B 模型

#### 特点
- **自动化数据收集**：无需人工标注，自动筛选高质量代码样本
- **多模型协作**：32B 生成 + 14B 验证 + 1.5B 部署的混合架构
- **持续优化**：通过微调实现模型的持续改进
- **智能分支**：通过关键词"自我演化"自动切换工作模式

### 5. 模型微调
- 使用收集的 (instruct, code) 数据对模型进行微调
- 支持自定义训练轮数和保存路径
- 实时显示训练进度和数据集状态

## 快速开始

### 环境要求
- Python 3.8+
- PyTorch 2.0+
- CUDA（可选，用于 GPU 加速）

### 安装依赖

```bash
pip install -r requirements.txt
```

主要依赖：
- `transformers>=4.30.0` - Hugging Face Transformers
- `torch>=2.0.0` - PyTorch
- `gradio>=4.0.0` - Web 界面
- `requests>=2.28.0` - API 调用
- `datasets>=2.0.0` - 数据处理（可选）
- `bitsandbytes>=0.41.0` - 量化加速（可选，GPU需要）

### 运行项目

1. **准备模型文件**
   - 将下载的模型放置在 `./models/` 目录下
   - 支持 Qwen2.5-Coder-0.5B-Instruct 和 Qwen2.5-Coder-1.5B

2. **启动应用**
   ```bash
   python gradio_local_model.py
   ```

3. **访问界面**
   - 浏览器打开显示的本地地址（通常是 `http://127.0.0.1:7860`）

### 使用指南

#### 普通代码生成
1. 点击"加载模型"按钮加载本地模型
2. 在"代码生成提示"中输入需求
3. 点击"生成代码"获取结果

#### 自我演化模式
1. 在"自我演化配置"中填写 API 密钥：
   - qwen2.5-coder-32b-instruct API Key 和 URL
   - qwen2.5-coder-14b-instruct API Key 和 URL
2. 在代码生成提示中包含"**自我演化**"关键词
3. 系统会自动收集高质量训练数据
4. 在"模型微调"区域使用收集的数据进行微调

#### 模型评估
1. 加载模型后，在"模型评估"区域设置评估任务数量
2. 点击"开始评估"查看模型在 HumanEval 数据集上的表现

## 创新点

### 1. 自我演化机制
- **首创性**：实现了代码生成模型的自动数据收集和持续优化
- **多模型协作**：利用不同规模模型的优势（32B生成、14B验证、1.5B部署）
- **自动化流程**：从代码生成到验证到微调的完整自动化

### 2. 智能分支判断
- 通过关键词自动识别用户意图
- 普通模式：快速生成代码
- 自我演化模式：收集高质量数据

### 3. 双重验证机制
- **语法验证**：确保代码可执行
- **逻辑验证**：确保代码符合需求
- 只有通过双重验证的代码才会被收集

### 4. 端到端优化
- 从数据收集到模型微调的完整闭环
- 支持模型的持续迭代和优化

## 项目结构

```
nlp_final/
├── gradio_local_model.py      # 主程序文件
├── models/                     # 模型文件目录
│   ├── Qwen2.5-Coder-0.5B-Instruct/
│   └── Qwen2.5-Coder-1.5B/
├── datasets/                   # 数据集目录
│   └── human-eval-v2-20210705.jsonl
├── requirements.txt           # 依赖列表
└── README.md                  # 项目说明
```

## 后续改进方向

### 1. 性能优化
- [ ] 实现模型量化（8-bit/4-bit）以提升推理速度
- [ ] 支持批处理生成，提高吞吐量
- [ ] 优化内存使用，支持更大规模的模型
- [ ] 集成 vLLM 等高性能推理引擎

### 2. 功能增强
- [ ] 支持更多编程语言（Java、C++、JavaScript等）
- [ ] 实现代码补全和自动修复功能
- [ ] 添加代码解释和文档生成功能
- [ ] 支持多文件项目生成

### 3. 自我演化优化
- [ ] 实现增量学习，支持在线微调
- [ ] 添加数据质量评分机制，自动筛选最优样本
- [ ] 支持多轮对话的复杂推理任务
- [ ] 实现主动学习，智能选择最有价值的训练样本

### 4. 评估体系完善
- [ ] 集成更多评估数据集（MBPP、APPS等）
- [ ] 添加代码质量评估指标（可读性、效率等）
- [ ] 实现自动化测试用例生成
- [ ] 支持自定义评估任务

### 5. 用户体验提升
- [ ] 添加代码历史记录和版本管理
- [ ] 实现代码分享和协作功能
- [ ] 支持代码导出和项目管理
- [ ] 添加使用统计和分析功能

### 6. 系统架构优化
- [ ] 支持分布式训练和推理
- [ ] 实现模型服务化部署（API服务）
- [ ] 添加用户认证和权限管理
- [ ] 实现数据持久化和备份机制

### 7. 研究拓展
- [ ] 探索强化学习在代码生成中的应用
- [ ] 研究代码生成的few-shot学习策略
- [ ] 实现代码生成的解释性和可解释性
- [ ] 探索多模态代码生成（结合自然语言和代码）

## 技术栈

- **深度学习框架**：PyTorch, Transformers
- **Web界面**：Gradio
- **模型**：Qwen2.5-Coder 系列
- **数据处理**：Hugging Face Datasets
- **评估基准**：HumanEval

**注意**：使用自我演化功能需要配置相应的 API 密钥。请确保 API 服务可用且有足够的配额。
