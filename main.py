"""
ä¸»ç¨‹åºå…¥å£
"""
import gradio as gr
from config import (
    DEFAULT_MODEL_PATH, 
    API_CONFIG, 
    EVOLUTION_CONFIG,
    GENERATION_CONFIG,
    EVALUATION_CONFIG,
    FINE_TUNE_CONFIG
)
from core.model_manager import load_model
from core.evolution_core import generate_code, batch_self_evolution
from core.model_evaluation import get_evaluation_help
from core.fine_tune_manager import get_fine_tune_help, get_fine_tune_status
from data.training_data import list_training_data
from ui.event_handlers import (
    update_api_config, 
    update_evolution_config,
    detect_mode, 
    test_problem_extraction,
    evaluate_model_wrapper,
    fine_tune_model_wrapper
)
from utils.text_utils import detect_evolution_mode


def create_gradio_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    with gr.Blocks(title="Qwen2.5-Coder æ‰¹é‡è‡ªæˆ‘æ¼”åŒ–ç³»ç»Ÿ", theme=gr.themes.Soft()) as demo:
        gr.Markdown("# Qwen2.5-Coder æ‰¹é‡è‡ªæˆ‘æ¼”åŒ–ç³»ç»Ÿ")
        gr.Markdown("""
        ## åŠŸèƒ½ç‰¹æ€§ï¼š
        1. **æ™®é€šä»£ç ç”Ÿæˆ**ï¼šä½¿ç”¨æœ¬åœ°1.5Bæ¨¡å‹ç”Ÿæˆä»£ç 
        2. **æ‰¹é‡è‡ªæˆ‘æ¼”åŒ–**ï¼šè¾“å…¥åŒ…å«å¤šä¸ªå¼•å·å†…çš„é—®é¢˜ï¼Œç³»ç»Ÿè‡ªåŠ¨æå–å¹¶æ‰¹é‡è®­ç»ƒ
        3. **æ™ºèƒ½é—®é¢˜æå–**ï¼šè‡ªåŠ¨ä»æ–‡æœ¬ä¸­æå–å¼•å·å†…çš„ç¼–ç¨‹é—®é¢˜
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### æ¨¡å‹è®¾ç½®")
                model_path_input = gr.Textbox(
                    label="æ¨¡å‹è·¯å¾„", value=DEFAULT_MODEL_PATH, lines=1
                )
                load_btn = gr.Button("åŠ è½½æ¨¡å‹", variant="primary", size="lg")
                load_status = gr.Textbox(label="æ¨¡å‹çŠ¶æ€", interactive=False, lines=3)
                
                with gr.Accordion("APIè®¾ç½®", open=False):
                    api_key_input = gr.Textbox(
                        label="APIå¯†é’¥", value=API_CONFIG["api_key"], type="password", lines=1
                    )
                    api_32b_url = gr.Textbox(
                        label="32B APIåœ°å€", value=API_CONFIG["qwen_32b_api_url"], lines=1
                    )
                    api_14b_url = gr.Textbox(
                        label="14B APIåœ°å€", value=API_CONFIG["qwen_14b_api_url"], lines=1
                    )
                
                with gr.Accordion("è‡ªæˆ‘æ¼”åŒ–è®¾ç½®", open=False):
                    enable_evolution = gr.Checkbox(
                        label="å¯ç”¨è‡ªæˆ‘æ¼”åŒ–", value=EVOLUTION_CONFIG["enable_self_evolution"]
                    )
                    evolution_keywords = gr.Textbox(
                        label="æ¼”åŒ–å…³é”®è¯", value=",".join(EVOLUTION_CONFIG["evolution_keywords"]), lines=2
                    )
                    batch_size = gr.Slider(
                        label="æ‰¹é‡å¤§å°", minimum=1, maximum=10, 
                        value=EVOLUTION_CONFIG["evolution_batch_size"], step=1
                    )
                    learning_rate = gr.Slider(
                        label="å­¦ä¹ ç‡", minimum=1e-6, maximum=1e-3, 
                        value=EVOLUTION_CONFIG["learning_rate"], step=1e-6
                    )
                
                with gr.Accordion("æ•°æ®ç®¡ç†", open=False):
                    with gr.Row():
                        view_data_btn = gr.Button("æŸ¥çœ‹è®­ç»ƒæ•°æ®", variant="secondary")
                        test_extraction_btn = gr.Button("æµ‹è¯•é—®é¢˜æå–", variant="secondary")
                    
                    training_data_view = gr.Textbox(
                        label="è®­ç»ƒæ•°æ®", interactive=False, lines=10
                    )
                
                with gr.Accordion("ç”Ÿæˆè®¾ç½®", open=False):
                    system_prompt_input = gr.Textbox(
                        label="ç³»ç»Ÿæç¤ºè¯",
                        value=GENERATION_CONFIG["default_system_prompt"],
                        lines=2
                    )
                    max_tokens_input = gr.Slider(
                        label="æœ€å¤§tokenæ•°", minimum=50, maximum=2048, 
                        value=GENERATION_CONFIG["default_max_tokens"], step=50
                    )
                    temperature_input = gr.Slider(
                        label="Temperature", minimum=0.1, maximum=2.0, 
                        value=GENERATION_CONFIG["default_temperature"], step=0.1
                    )
                    top_p_input = gr.Slider(
                        label="Top-p", minimum=0.1, maximum=1.0, 
                        value=GENERATION_CONFIG["default_top_p"], step=0.05
                    )
                
                with gr.Accordion("æ¨¡å‹è¯„ä¼°", open=False):
                    gr.Markdown("### HumanEval æ•°æ®é›†è¯„ä¼°")
                    with gr.Row():
                        eval_max_tasks = gr.Number(
                            label="è¯„ä¼°ä»»åŠ¡æ•°é‡",
                            value=EVALUATION_CONFIG["default_max_tasks"],
                            minimum=1,
                            maximum=164,
                            step=1,
                            info="è¾“å…¥è¦è¯„ä¼°çš„ä»»åŠ¡æ•°é‡ï¼ˆ1-164ï¼‰"
                        )
                        eval_all_check = gr.Checkbox(
                            label="è¯„ä¼°å…¨éƒ¨ä»»åŠ¡",
                            value=False,
                            info="å‹¾é€‰æ­¤é¡¹å°†è¯„ä¼°æ‰€æœ‰164ä¸ªä»»åŠ¡"
                        )
                    
                    with gr.Row():
                        eval_max_tokens = gr.Slider(
                            label="æœ€å¤§ç”Ÿæˆtoken",
                            minimum=50,
                            maximum=2048,
                            value=EVALUATION_CONFIG["default_max_tokens"],
                            step=50
                        )
                        eval_temperature = gr.Slider(
                            label="Temperature",
                            minimum=0.1,
                            maximum=2.0,
                            value=EVALUATION_CONFIG["default_temperature"],
                            step=0.1
                        )
                        eval_top_p = gr.Slider(
                            label="Top-p",
                            minimum=0.1,
                            maximum=1.0,
                            value=EVALUATION_CONFIG["default_top_p"],
                            step=0.05
                        )
                    
                    eval_btn = gr.Button("ğŸš€ å¼€å§‹è¯„ä¼°", variant="secondary", size="lg")
                    eval_output = gr.Markdown(label="è¯„ä¼°ç»“æœ")
                    
                    with gr.Accordion("ğŸ“– è¯„ä¼°è¯´æ˜", open=False):
                        eval_help_text = get_evaluation_help()
                        gr.Markdown(eval_help_text)
                
                with gr.Accordion("æ¨¡å‹å¾®è°ƒ", open=False):
                    gr.Markdown("### ä½¿ç”¨æ”¶é›†çš„æ•°æ®å¾®è°ƒæ¨¡å‹")
                    
                    fine_tune_output_dir = gr.Textbox(
                        label="æ¨¡å‹ä¿å­˜è·¯å¾„",
                        value=FINE_TUNE_CONFIG["default_output_dir"],
                        placeholder="./fine_tuned_model",
                        info="å¾®è°ƒåæ¨¡å‹çš„ä¿å­˜è·¯å¾„"
                    )
                    
                    with gr.Row():
                        fine_tune_epochs = gr.Slider(
                            label="è®­ç»ƒè½®æ•°",
                            minimum=1,
                            maximum=10,
                            value=FINE_TUNE_CONFIG["default_num_epochs"],
                            step=1,
                            info="å¾®è°ƒçš„è®­ç»ƒè½®æ•°"
                        )
                        fine_tune_batch_size = gr.Slider(
                            label="æ‰¹å¤§å°",
                            minimum=1,
                            maximum=8,
                            value=FINE_TUNE_CONFIG["default_batch_size"],
                            step=1,
                            info="æ¯æ‰¹å¤„ç†çš„æ ·æœ¬æ•°"
                        )
                        fine_tune_lr = gr.Slider(
                            label="å­¦ä¹ ç‡",
                            minimum=1e-6,
                            maximum=1e-3,
                            value=FINE_TUNE_CONFIG["default_learning_rate"],
                            step=1e-6,
                            info="æ¨¡å‹å­¦ä¹ ç‡"
                        )
                    
                    fine_tune_btn = gr.Button("ğŸš€ å¼€å§‹å¾®è°ƒ", variant="secondary", size="lg")
                    fine_tune_output = gr.Markdown(label="å¾®è°ƒç»“æœ")
                    fine_tune_status = gr.Markdown(get_fine_tune_status)
                    
                    with gr.Accordion("ğŸ“– å¾®è°ƒè¯´æ˜", open=False):
                        fine_tune_help_text = get_fine_tune_help()
                        gr.Markdown(fine_tune_help_text)
            
            with gr.Column(scale=2):
                gr.Markdown("### ä»£ç ç”Ÿæˆä¸è‡ªæˆ‘æ¼”åŒ–")
                
                mode_indicator = gr.Markdown("**å½“å‰æ¨¡å¼ï¼š** ç­‰å¾…è¾“å…¥...")
                
                # ç¤ºä¾‹è¾“å…¥
                example_input = '''è¯·è‡ªæˆ‘æ¼”åŒ–
    "Write a function to find the minimum cost path to reach (m, n) from (0, 0) for the given cost matrix cost[][] and a position (m, n) in cost[][]."
    "Write a function to find the similar elements from the given two tuple lists."
    "Write a python function to identify non-prime numbers."
    "Write a function to find the largest integers from a given list of numbers using heap queue algorithm."
    "Write a function to find the number of ways to fill it with 2 x 1 dominoes for the given 3 x n board."'''
                
                prompt_input = gr.Textbox(
                    label="è¾“å…¥æç¤ºè¯",
                    placeholder=example_input,
                    lines=10,
                    value=example_input
                )
                
                with gr.Row():
                    generate_btn = gr.Button("ç”Ÿæˆä»£ç ", variant="primary", size="lg")
                    evolve_btn = gr.Button("æ‰§è¡Œè‡ªæˆ‘æ¼”åŒ–", variant="stop", size="lg")
                
                status_output = gr.Textbox(
                    label="æ‰§è¡ŒçŠ¶æ€", interactive=False, lines=12
                )
                
                code_output = gr.Code(
                    label="ç”Ÿæˆçš„ä»£ç ", language="python", lines=20
                )
        
        # ====== ç»‘å®šäº‹ä»¶ ======
        load_btn.click(
            fn=load_model,
            inputs=model_path_input,
            outputs=load_status
        )
        
        generate_btn.click(
            fn=generate_code,
            inputs=[
                prompt_input, system_prompt_input, max_tokens_input, 
                temperature_input, top_p_input, enable_evolution
            ],
            outputs=[status_output, code_output]
        ).then(
            fn=detect_mode,
            inputs=prompt_input,
            outputs=mode_indicator
        )
        
        evolve_btn.click(
            fn=generate_code,
            inputs=[
                prompt_input, system_prompt_input, max_tokens_input, 
                temperature_input, top_p_input, enable_evolution
            ],
            outputs=[status_output, code_output]
        ).then(
            fn=detect_mode,
            inputs=prompt_input,
            outputs=mode_indicator
        )
        
        # APIé…ç½®æ›´æ–°
        api_key_input.change(
            fn=update_api_config,
            inputs=[api_key_input, api_32b_url, api_14b_url],
            outputs=gr.Textbox(visible=False)
        )
        
        # æ¼”åŒ–é…ç½®æ›´æ–°
        enable_evolution.change(
            fn=update_evolution_config,
            inputs=[enable_evolution, evolution_keywords, batch_size, learning_rate],
            outputs=gr.Textbox(visible=False)
        )
        
        # æŸ¥çœ‹è®­ç»ƒæ•°æ®
        view_data_btn.click(
            fn=list_training_data,
            outputs=training_data_view
        )
        
        # æµ‹è¯•é—®é¢˜æå–
        test_extraction_btn.click(
            fn=test_problem_extraction,
            inputs=prompt_input,
            outputs=training_data_view
        )
        
        # å®æ—¶æ£€æµ‹æ¨¡å¼
        prompt_input.change(
            fn=detect_mode,
            inputs=prompt_input,
            outputs=mode_indicator
        )
        
        # ç»‘å®šè¯„ä¼°äº‹ä»¶
        eval_btn.click(
            fn=evaluate_model_wrapper,
            inputs=[eval_max_tasks, eval_all_check, eval_max_tokens, eval_temperature, eval_top_p],
            outputs=eval_output
        )
        
        # ç»‘å®šå¾®è°ƒäº‹ä»¶
        fine_tune_btn.click(
            fn=fine_tune_model_wrapper,
            inputs=[fine_tune_output_dir, fine_tune_epochs, fine_tune_batch_size, fine_tune_lr],
            outputs=fine_tune_output
        ).then(
            fn=lambda: get_fine_tune_status(),
            outputs=fine_tune_status
        )
        
        # ç¤ºä¾‹æç¤ºè¯
        gr.Examples(
            examples=[
                [example_input],
                ["è¯·è‡ªæˆ‘æ¼”åŒ–\n\"ç”¨Pythonå®ç°ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•ã€‚\"\n\"ç”¨Pythonå®ç°ä¸€ä¸ªäºŒå‰æ ‘çš„éå†ç®—æ³•ã€‚\""],
                ["ç”¨Pythonç¼–å†™ä¸€ä¸ªç®€å•çš„HTTPæœåŠ¡å™¨ã€‚"],
            ],
            inputs=prompt_input,
            outputs=[mode_indicator]
        )
        
        # ä½¿ç”¨è¯´æ˜
        gr.Markdown("""
        ## åŠŸèƒ½è¯´æ˜

        ### 1. æ¨¡å‹åŠ è½½
        - é€‰æ‹©æˆ–è¾“å…¥æœ¬åœ°æ¨¡å‹è·¯å¾„
        - ç‚¹å‡»"åŠ è½½æ¨¡å‹"æŒ‰é’®
        - æ¨¡å‹åŠ è½½åæ‰èƒ½è¿›è¡Œå…¶ä»–æ“ä½œ
        
        ### 2. æ™®é€šä»£ç ç”Ÿæˆ
        - è¾“å…¥ä»£ç ç”Ÿæˆæç¤ºï¼ˆä¸åŒ…å«æ¼”åŒ–å…³é”®è¯ï¼‰
        - ç‚¹å‡»"ç”Ÿæˆä»£ç "æŒ‰é’®
        - æ¨¡å‹ä¼šç”Ÿæˆç›¸åº”çš„ä»£ç 
        
        ### 3. æ‰¹é‡è‡ªæˆ‘æ¼”åŒ–
        - åœ¨è¾“å…¥ä¸­åŒ…å«"è‡ªæˆ‘æ¼”åŒ–"å…³é”®è¯
        - ç”¨**åŒå¼•å·**æ‹¬èµ·æ¯ä¸ªç¼–ç¨‹é—®é¢˜
        - ç‚¹å‡»"æ‰§è¡Œè‡ªæˆ‘æ¼”åŒ–"æŒ‰é’®
        - ç³»ç»Ÿä¼šè‡ªåŠ¨æå–é—®é¢˜å¹¶è¿›è¡Œè®­ç»ƒ
        
        ### 4. æ¨¡å‹è¯„ä¼°
        - é€‰æ‹©è¯„ä¼°ä»»åŠ¡æ•°é‡ï¼ˆå»ºè®®å…ˆç”¨10ä¸ªæµ‹è¯•ï¼‰
        - ç‚¹å‡»"å¼€å§‹è¯„ä¼°"æŒ‰é’®
        - ç³»ç»Ÿä¼šåœ¨HumanEvalæ•°æ®é›†ä¸Šè¯„ä¼°æ¨¡å‹
        - æ”¯æŒæµå¼è¾“å‡ºï¼Œå¯å®æ—¶æŸ¥çœ‹è¿›åº¦
        
        ### 5. æ¨¡å‹å¾®è°ƒ
        - é¦–å…ˆä½¿ç”¨è‡ªæˆ‘æ¼”åŒ–åŠŸèƒ½æ”¶é›†è®­ç»ƒæ•°æ®
        - é…ç½®å¾®è°ƒå‚æ•°ï¼ˆè®­ç»ƒè½®æ•°ã€æ‰¹å¤§å°ã€å­¦ä¹ ç‡ï¼‰
        - ç‚¹å‡»"å¼€å§‹å¾®è°ƒ"æŒ‰é’®
        - ç³»ç»Ÿä¼šç”¨æ”¶é›†çš„æ•°æ®å¾®è°ƒæ¨¡å‹
        
        ### 6. æ•°æ®ç®¡ç†
        - æŸ¥çœ‹è®­ç»ƒæ•°æ®ï¼šæŸ¥çœ‹å·²æ”¶é›†çš„è®­ç»ƒæ•°æ®
        - æµ‹è¯•é—®é¢˜æå–ï¼šæµ‹è¯•ä»è¾“å…¥ä¸­æå–é—®é¢˜çš„èƒ½åŠ›
        
        ## å·¥ä½œæµç¨‹å»ºè®®
        
        1. **é¦–æ¬¡ä½¿ç”¨**
           - åŠ è½½é»˜è®¤æ¨¡å‹
           - è¿›è¡Œå‡ æ¬¡æ™®é€šä»£ç ç”Ÿæˆæµ‹è¯•
           - è¿è¡Œæ¨¡å‹è¯„ä¼°ï¼ˆå°‘é‡ä»»åŠ¡ï¼‰
        
        2. **æ•°æ®æ”¶é›†**
           - è¿›è¡Œè‡ªæˆ‘æ¼”åŒ–æ”¶é›†é«˜è´¨é‡è®­ç»ƒæ•°æ®
           - è§‚å¯Ÿç”Ÿæˆçš„ä»£ç è´¨é‡
           - ä¿®æ”¹æç¤ºè¯ä»¥è·å¾—æ›´å¥½çš„ç»“æœ
        
        3. **æ¨¡å‹å¾®è°ƒ**
           - æ”¶é›†20-50æ¡è®­ç»ƒæ•°æ®åè¿›è¡Œå¾®è°ƒ
           - ä½¿ç”¨é»˜è®¤å‚æ•°ï¼ˆ3è½®epochï¼‰
           - å¾®è°ƒå®Œæˆåé‡æ–°åŠ è½½å¾®è°ƒæ¨¡å‹
        
        4. **æ€§èƒ½å¯¹æ¯”**
           - å¾®è°ƒå‰ååˆ†åˆ«è¿›è¡Œè¯„ä¼°
           - å¯¹æ¯”é€šè¿‡ç‡æ˜¯å¦æœ‰æå‡
           - æ ¹æ®ç»“æœè°ƒæ•´è®­ç»ƒæ•°æ®æˆ–å‚æ•°
        
        5. **æŒç»­ä¼˜åŒ–**
           - å®šæœŸæ”¶é›†æ–°çš„è®­ç»ƒæ•°æ®
           - è¿›è¡Œå¢é‡å¾®è°ƒï¼ˆç»§ç»­è®­ç»ƒï¼‰
           - è¯„ä¼°æ€§èƒ½æ”¹è¿›æƒ…å†µ
        """)
    
    return demo


if __name__ == "__main__":
    # å¯åŠ¨ Gradio ç•Œé¢
    demo = create_gradio_interface()
    demo.launch(
        share=False, 
        server_name="0.0.0.0", 
        server_port=7860,
        show_api=False
    )