"""
äº‹ä»¶å¤„ç†å‡½æ•°
"""
from core.model_manager import load_model
from utils.text_utils import detect_evolution_mode, extract_problems_from_text
from config import API_CONFIG, EVOLUTION_CONFIG, GENERATION_CONFIG


def update_api_config(api_key, api_70b, api_14b):
    """æ›´æ–°APIé…ç½®"""
    API_CONFIG["api_key"] = api_key
    API_CONFIG["qwen_70b_api_url"] = api_70b
    API_CONFIG["qwen_14b_api_url"] = api_14b
    return "âœ… APIé…ç½®å·²æ›´æ–°"


def update_evolution_config(enable, keywords, batch, lr):
    """æ›´æ–°è‡ªæˆ‘æ¼”åŒ–é…ç½®"""
    EVOLUTION_CONFIG["enable_self_evolution"] = enable
    EVOLUTION_CONFIG["evolution_keywords"] = [k.strip() for k in keywords.split(",") if k.strip()]
    EVOLUTION_CONFIG["evolution_batch_size"] = batch
    EVOLUTION_CONFIG["learning_rate"] = lr
    return "âœ… è‡ªæˆ‘æ¼”åŒ–é…ç½®å·²æ›´æ–°"


def detect_mode(prompt):
    """æ£€æµ‹å½“å‰æ¨¡å¼"""
    if not prompt:
        return "**å½“å‰æ¨¡å¼ï¼š** ç­‰å¾…è¾“å…¥..."
    
    should_evolve, problems = detect_evolution_mode(prompt)
    
    if should_evolve:
        if problems:
            return f"**å½“å‰æ¨¡å¼ï¼š** ğŸš€ æ‰¹é‡è‡ªæˆ‘æ¼”åŒ–æ¨¡å¼ï¼ˆæ£€æµ‹åˆ°{len(problems)}ä¸ªé—®é¢˜ï¼‰"
        else:
            return "**å½“å‰æ¨¡å¼ï¼š** ğŸ”„ å•é—®é¢˜è‡ªæˆ‘æ¼”åŒ–æ¨¡å¼"
    
    return "**å½“å‰æ¨¡å¼ï¼š** ğŸ’» æ™®é€šä»£ç ç”Ÿæˆæ¨¡å¼"


def test_problem_extraction(prompt):
    """æµ‹è¯•é—®é¢˜æå–"""
    should_evolve, problems = detect_evolution_mode(prompt)
    
    if not should_evolve:
        return "æœªæ£€æµ‹åˆ°è‡ªæˆ‘æ¼”åŒ–å…³é”®è¯ã€‚"
    
    if not problems:
        return "æ£€æµ‹åˆ°è‡ªæˆ‘æ¼”åŒ–å…³é”®è¯ï¼Œä½†æ²¡æœ‰æå–åˆ°é—®é¢˜ã€‚"
    
    result = f"âœ… æ£€æµ‹åˆ°è‡ªæˆ‘æ¼”åŒ–æ¨¡å¼\n"
    result += f"ğŸ“‹ æå–åˆ° {len(problems)} ä¸ªé—®é¢˜ï¼š\n\n"
    
    for i, problem in enumerate(problems, 1):
        result += f"{i}. {problem}\n"
    
    result += f"\næç¤ºï¼šç‚¹å‡»'æ‰§è¡Œè‡ªæˆ‘æ¼”åŒ–'æŒ‰é’®å¼€å§‹æ‰¹é‡è®­ç»ƒã€‚"
    return result